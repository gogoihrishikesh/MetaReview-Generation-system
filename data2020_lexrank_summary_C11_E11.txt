The paper focuses on value-based RL approaches. The authors need to make these much more clear, and should clearly state the main setting/model that the paper is considering (which seems to be the concurrent discrete-time case, but also not very clear to me). The explanation of concurrent actions in continuous and discrete time is not clear. As an example of a different approach towards the problem, which the authors overlook in their related work section, is that of learning with spiking neurons and point processes. [1]: Vasilaki, Eleni, et al. "Spike-based reinforcement learning in continuous state and action space: when policy gradient methods fail." 